// Slurm HPC Scheduler Execution Profile
// For running on high-performance computing clusters with Slurm

profiles {
    slurm {
        process {
            executor = 'slurm'
            
            // Resource specifications (Slurm-compatible)
            cpus   = { check_max( 4 * task.attempt, 'cpus' ) }
            memory = { check_max( 16.GB * task.attempt, 'memory' ) }
            time   = { check_max( 12.h * task.attempt, 'time' ) }
            
            // Slurm directives
            clusterOptions = '--job-name=scrnaseq'
            
            // Process-specific resources
            withLabel: process_low {
                cpus   = { check_max( 2, 'cpus' ) }
                memory = { check_max( 4.GB * task.attempt, 'memory' ) }
                time   = { check_max( 4.h * task.attempt, 'time' ) }
                queue  = 'normal'
            }
            
            withLabel: process_medium {
                cpus   = { check_max( 4, 'cpus' ) }
                memory = { check_max( 16.GB * task.attempt, 'memory' ) }
                time   = { check_max( 12.h * task.attempt, 'time' ) }
                queue  = 'normal'
            }
            
            withLabel: process_high {
                cpus   = { check_max( 8, 'cpus' ) }
                memory = { check_max( 32.GB * task.attempt, 'memory' ) }
                time   = { check_max( 24.h * task.attempt, 'time' ) }
                queue  = 'long'  // Use longer queue for intensive tasks
            }
        }
        
        // Slurm executor configuration
        executor {
            name = 'slurm'
            queueSize = 20              // Number of jobs to queue at once
            submitRateLimit = '2 sec'   // Rate limit for job submission
            pollInterval = '30 sec'     // Check job status every 30 seconds
            dumpInterval = '5 min'      // Log task info every 5 minutes
            exitReadTimeout = '270 sec' // Wait for task completion
        }
        
        // Slurm-specific settings
        slurm {
            queueStatInterval = '30 sec'
            submitRateLimit = '2 sec'
        }
        
        // Container configuration for HPC
        // Most HPC clusters support Singularity
        singularity {
            enabled = true
            autoMounts = true
            cacheDir = "${System.getenv('HOME')}/.singularity-cache"
            pullTimeout = '20 min'
        }
        
        docker.enabled = false  // Usually not available on HPC
        conda.enabled = false   // Use containers instead
        
        // Local scratch space for temporary files
        process.scratch = '/scratch/$USER'  // If available on your cluster
        
        // Optional: Use environment modules for dependency management
        // module load singularity
        // module load python
        // etc.
    }
}
